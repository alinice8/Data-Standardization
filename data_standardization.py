# -*- coding: utf-8 -*-
"""Data Standardization.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1vBk3ljbawGlzqf8t0g0kFwPdgbIjTNVS

**Data Standardization:**
T**he process of standardizing the data to a common format and common range.**So whats its mean lets say we have a dataset and this dataset contains 10 column of data and their is a posibility that each columns contain data in different range for example: one column can contain data in the range of 200 and the one column can contain the data in the range of thousands and two thousands and one colimn can contain data in tens or twenties so we need to standardize this data in to a common format and to a common range before feeding it to a machine learning alograthim because its easier to do analyze or analysis and the processing on this standard data instead of having an un standard data.

first we are importing some libraries numpy is useful for creating numpy arrays.Pandas it is useful to create data frames that is structured data which is use to more help in analysis so the standard sclar function in which we are going to use standardize our datasets.Training and testing data from sklearn dataset we get the sample of dataset.
"""

import numpy as np
import pandas as pd
import sklearn.datasets
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split

"""# loading the dataset
So their is a data of breast cancer that the breast cancer yes or no.
"""

dataset = sklearn.datasets.load_breast_cancer()

print(dataset)

"""Data set Description:
In the dataset you will see the parameters which we will analyze to predict whether a person has breast cancer or not so their is a target variables zero represents that the person has breast cancer in begin stage and one represents that the person is in maligant stage. maligant is an advance stage that this is more critical stage.We have also feature names. 
"""



"""# loading the data to a panda dataframe."""

df = pd.DataFrame(dataset.data, columns= dataset.feature_names)

df.head()

df.shape

X = df
Y = dataset.target

print(X)

"""So the X is a data frame and the Y is the target value or label value so the values are either 0 or 1 we dont want to standardize the Y data because their is already two variables we have to standardize the data of X to get some common range."""

print(Y)

"""# Splitting the data into training data and test data."""

X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=3)

print(X.shape, X_train.shape, X_test.shape)

"""# Standardize the data 
If our data has all the values in the same range the standard deviation should be one so here is standard deviation is 228 so we can say that the data in no the same range.
"""

print(dataset.data.std())

"""To standardize the data we are using the library of standard scalar 
scalar dot preprocessing so you can see how the data is standardize so their is a formula z=(x-u)/s that tell us that each data point taken and the mean will be subtratracted from its means ( the u represents the mean) and the s represents the scalar deviation or standard deviation. when u apply this formula it does not affect the nature of the data it only change the value range 
"""

scaler = StandardScaler()

scaler.fit(X_train)

X_train_standardized = scaler.transform(X_train)

print(X_train_standardized)

"""You can see these values are very close to each other between 0 and 1 but as you can see previous the X have values seventeen , twenty and have thousands and two thousands etc. Now you can see that the values are in similar range """

X_test_standardized = scaler.transform(X_test)

print(X_train_standardized.std())